# SAR_Project: 基于半监督学习的 SAR 地面目标识别

## 项目概述

本项目旨在使用半监督学习方法进行 SAR（合成孔径雷达）图像的地面目标识别。
SAR 图像因其具有高分辨率和多角度视图的特点，
广泛应用于地面目标的检测与识别。
然而，SAR 图像也面临噪声、目标多样性、几何失真和环境因素等挑战。
本项目通过半监督学习技术，结合 MixUp 和 FixMatch 等方法，
提高模型在 SAR 图像中地面目标识别的精度。

## SAR 图像挑战

SAR 图像在获取过程中涉及雷达信号的反射和回波的解析，其特点包括：
- **噪声和干扰**：SAR 图像常常受到斑点噪声等影响，降低图像清晰度和目标可检测性。
- **目标多样性**：不同地面目标的外观可能十分相似，增加了目标的区分难度。
- **几何失真**：由于雷达波传播的方式，SAR 图像可能会出现几何失真，需要进行校正。
- **环境因素**：天气、地形、时间等因素对图像质量的影响。

### 目标类别
- **2S1**：自行火炮系统
- **BMP2**：步兵战车
- **T62**：T-62 型坦克
- **BTR60、BTR70**：不同型号的装甲车
- **ZIL131**：军用卡车
- **BRDM_2、ZSU_23_4**：其他军用车辆
- .....

## 项目时间规划

| 时间         | 任务                                               |
|--------------|----------------------------------------------------|
| 第1天上午    | 配置环境，完成数据处理与分析                       |
| 第1天下午    | 实现 MixUp 或 MixMatch                           |
| 第2天上午    | 完成 FixMatch，并设计网络结构                      |
| 第2天下午    | 训练模型并调参，生成检测结果                       |
| 第3天上午    | 实现界面系统，完成推理功能                        |
| 第3天下午    | 总结项目，整理文档，撰写 `README.md`               |

## 环境配置与依赖
  ```bash
        pip install -r requirements.txt
  ```

## 安装依赖

在开始项目之前，确保已安装 Python 和相关的依赖库。可以通过以下命令安装项目所需的依赖：

## FixMatch vs MixUp 对比

| **特点**             | **FixMatch**                            | **MixUp**                                 |
|----------------------|-----------------------------------------|-------------------------------------------|
| **核心思想**         | 利用无标签数据的伪标签进行训练           | 通过线性组合生成合成样本，增强数据多样性   |
| **优点**             | 高效利用无标签数据，提升泛化能力        | 平滑决策边界，减少过拟合                  |
| **缺点**             | 依赖高质量的伪标签，伪标签噪声可能影响效果 | 生成标签模糊，可能影响模型的理解         |
| **适用数据量**       | 中等到大规模数据集，尤其是无标签数据较多  | 适合大规模数据集，尤其是数据多样性较高时  |
| **适用场景**         | 无标签数据占比较大，标签数据较少的场景   | 数据集较大，且具有较高多样性的数据集     |

## 适用场景与选择建议

### FixMatch
- **适合场景**：
  - 无标签数据占比较大，标签数据较少时，FixMatch 可以有效提高训练效果。
  - 数据集规模中等到大时（几千到几十万样本）。
  - 数据质量较高，能够提供较为准确的伪标签。
  
- **选择建议**：
  - 如果无标签数据量大且质量较高，可以选择 FixMatch。对于中等规模的无标签数据集，它能够有效地提升模型性能。

### MixUp
- **适合场景**：
  - 数据集较大，且具有较高的多样性。
  - 适用于处理分类任务，尤其是在数据不平衡或者包含噪声时，能够增强数据的多样性并减少过拟合。

- **选择建议**：
  - 如果数据集较大且包含多样化的样本，可以选择 MixUp。它能帮助模型更好地泛化并平滑决策边界，减少过拟合。

## 总结
- **FixMatch** 适合无标签数据占比大的场景，尤其是在数据集较大且噪声较少的情况下非常有效。
- **MixUp** 适合用于大规模数据集，尤其是数据多样性丰富的情况下，能够减少过拟合并提高泛化能力。

# ResNet-18 vs MobileNetV2 对比

## 概述

ResNet-18 和 MobileNetV2 都是广泛使用的深度学习模型架构，适用于图像分类和目标检测任务。它们各自具有不同的设计理念和优势，适用于不同的场景和硬件环境。

## 特点对比

| 特性           | ResNet-18                                                | MobileNetV2                                               |
|----------------|----------------------------------------------------------|----------------------------------------------------------|
| **核心思想**    | 利用深度残差网络进行特征提取，采用跳跃连接避免梯度消失问题      | 采用深度可分离卷积，减少计算量和参数量，适用于轻量级模型         |
| **优点**        | 提供更高的精度，适合复杂任务，能够捕获更高层次的特征            | 计算效率高，适合计算资源有限的设备，推理速度快                   |
| **缺点**        | 计算量大，参数量多，需要更多计算资源                        | 精度相对较低，适合任务不复杂或计算资源有限时使用                 |
| **适用数据量**  | 适用于大数据集，尤其是需要高精度的任务                        | 适用于小数据集或计算资源有限的场景                           |
| **适用场景**    | 适合大规模图像分类、检测任务，需要高精度模型的场景             | 适用于移动端、嵌入式设备，计算资源有限的任务                    |

## 适用场景与选择建议

### ResNet-18

- **适合场景**：
    - 任务较为复杂，数据量较大，需要高精度的图像分类、目标检测任务。
    - 计算资源充足，能够承受较大的计算负担。
    - 数据集较大（几百万至上亿样本），希望提取更复杂的特征。

- **选择建议**：
    - 如果需要高精度，且具备充足的计算资源，选择 **ResNet-18**。它适合用于复杂场景，特别是在大规模数据集上能够充分发挥其优势。

### MobileNetV2

- **适合场景**：
    - 计算资源有限的场景，如嵌入式设备、移动端应用。
    - 数据集较小（几十万到几百万样本），且对推理速度有较高要求。
    - 需要平衡计算效率与精度，避免过拟合。

- **选择建议**：
    - 如果需要高效推理并且计算资源有限，选择 **MobileNetV2**。它在移动设备上表现优异，适合轻量级应用。

## 总结

- **ResNet-18**：适合大规模数据集和计算资源丰富的环境，能够提供更高的精度和复杂特征提取能力。
- **MobileNetV2**：适用于计算资源有限的场景，如移动端或嵌入式设备，在小数据集和轻量级任务中表现优异。

## 推荐训练参数
针对万张左右数据集，以下是主要超参数推荐：

### 批次大小（Batch Size）
- 推荐值：32、64 或 128
- 说明：根据 GPU 显存情况调整，通常 32 是通用选择。

### 学习率（Learning Rate）
- 推荐值：1e-3（Adam 优化器默认值）
- 调整：若训练过程不稳定，可尝试减小到 1e-4 或 5e-5。

### 学习率调度器（Learning Rate Scheduler）
- 推荐策略：
  - StepLR（每 5 个 epoch 学习率衰减 10%，`step_size=5, gamma=0.1`）
  - CosineAnnealingLR（适用于长时间训练）

### 优化器（Optimizer）
- 推荐值：Adam 或 AdamW（适合大规模数据集）
- 参数：`lr=1e-3`

# 数据增强（Data Augmentation）

此项目使用了常见的图像数据增强方法，旨在增强模型的鲁棒性和泛化能力。
通过使用PyTorch的`torchvision.transforms`模块，我们对训练图像进行了以下增强处理：

## 数据增强策略

### 1. 随机旋转（RandomRotation）
- **功能**：随机旋转图像，旋转角度在-30到30度之间。
- **代码**：`transforms.RandomRotation(30)`
- **作用**：此操作有助于模拟图像旋转不一致的情况，增强模型对旋转的鲁棒性。

### 2. 随机裁剪并调整大小（RandomResizedCrop）
- **功能**：随机裁剪图像并调整为指定大小（224x224）。
- **代码**：`transforms.RandomResizedCrop(224)`
- **作用**：此方法能够模拟不同尺度下的物体，并将图像调整为一致的大小（224x224），以适应深度学习模型的输入要求。

### 3. 随机水平翻转（RandomHorizontalFlip）
- **功能**：以50%的概率对图像进行随机水平翻转。
- **代码**：`transforms.RandomHorizontalFlip()`
- **作用**：水平翻转是图像增强中常用的技术，适用于物体左右对称的情况。

### 4. 随机亮度和对比度调整（ColorJitter）
- **功能**：随机调整图像的亮度和对比度，亮度和对比度的变化范围为0.5。
- **代码**：`transforms.ColorJitter(brightness=0.5, contrast=0.5)`
- **作用**：此操作有助于提高模型对不同光照条件下图像的适应性。

### 5. 转换为张量（ToTensor）
- **功能**：将PIL图像或NumPy数组转换为PyTorch的Tensor格式。
- **代码**：`transforms.ToTensor()`
- **作用**：这是PyTorch中的标准转换步骤，将图像数据转换为Tensor格式，并将像素值归一化到[0, 1]区间。

### 6. 训练轮数（Epochs）
- 推荐值：10-50
- 说明：监控损失和准确率变化，必要时增加轮数。

### 7. 伪标签阈值（Pseudo-label Threshold）
- 推荐值：0.9 至 0.95

### 8. 正则化（Regularization）
- 权重衰减：`weight_decay=1e-4`
- 说明：增加 Dropout 或 weight_decay 可改善泛化能力。

### 9. GPU 显存使用
- 调整 `batch_size` 以适配显存大小。
- 使用 `pin_memory=True` 加速数据加载。
- 显存不足时可采用 Gradient Accumulation。

### 10 .模型架构
- 推荐：ResNet18（基础模型）或更深的网络如 ResNet50/ResNet101。
- 说明：根据任务复杂度选择合适的模型。

### 11.分布式训练（Optional）
- 若有多 GPU 可用，建议使用 `torch.nn.DataParallel` 或 `torch.nn.parallel.DistributedDataParallel` 加速训练。



## 12. 完整的数据增强代码示例

```python
import torch
from torchvision import transforms

transform = transforms.Compose([
    transforms.RandomRotation(30),  # 随机旋转图像
    transforms.RandomResizedCrop(224),  # 随机裁剪并调整大小
    transforms.RandomHorizontalFlip(),  # 随机水平翻转
    transforms.ColorJitter(brightness=0.5, contrast=0.5),  # 随机调整亮度与对比度
    transforms.ToTensor(),  # 转换为张量
])
```




